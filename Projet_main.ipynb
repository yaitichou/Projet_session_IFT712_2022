{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFT712 - Projet de fin de session\n",
    "\n",
    "## Sujet\n",
    "\n",
    "Classification de feuilles d'arbres en utilisant la bibliothèque Sklearn et comparaison des classifieurs présents dans celle-ci pour trouver le modèle adapté à l'étude des plantes. Pour ce faire, on utilisera la validation croisée et la recherche d’hyperparamètres pour chacuns des classifieurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equipe 8 :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Imporation of python libraries\n",
    "'''\n",
    "from LogisticRegression_classifieur import LogisticRegressionClassifier\n",
    "from knn_classifier import KNNClassifier\n",
    "from decision_trees_classifier import DTSClassifier\n",
    "from adaboost_classifieur import adaboostClassifier\n",
    "from svm_classifieur import svmClassifier\n",
    "from neural_network_classifier import NNClassifier\n",
    "from random_forest_classifieur import RandForestClassifier\n",
    "from data_manager import data_extract\n",
    "from data_manager import data_cleaning\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# 1. Préparation des données\n",
    "\n",
    "On utilise les données de classification de feuilles du site [Kaggle](https://www.kaggle.com/c/leaf-classification/data).\n",
    "Les données sont composées de 2 ensembles (train et test). \n",
    "\n",
    "Chaque échantillons est caractérisé par :\n",
    "- un id unique par image \n",
    "- 64 attributs pour la marge de la feuille\n",
    "- 64 attributs pour la forme de la feuille\n",
    "- 64 attributs pour la texture de la feuille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
      "0    0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
      "1    0.005859         0   0.03125  0.015625  0.025391  0.001953  0.019531   \n",
      "2    0.005859  0.009766  0.019531  0.007812  0.003906  0.005859  0.068359   \n",
      "3           0  0.003906  0.023438  0.005859  0.021484  0.019531  0.023438   \n",
      "4    0.005859  0.003906  0.048828  0.009766  0.013672  0.015625  0.005859   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "985  0.060547   0.11914  0.007812  0.003906         0   0.14844  0.017578   \n",
      "986  0.001953  0.003906  0.021484   0.10742  0.001953         0         0   \n",
      "987  0.001953  0.003906         0  0.021484  0.078125  0.003906  0.007812   \n",
      "988         0         0  0.046875  0.056641  0.009766         0         0   \n",
      "989  0.023438  0.019531   0.03125  0.015625  0.005859  0.019531  0.035156   \n",
      "\n",
      "    margin8   margin9  margin10  ... texture55 texture56 texture57 texture58  \\\n",
      "0         0  0.001953  0.033203  ...  0.007812         0   0.00293   0.00293   \n",
      "1         0         0  0.007812  ...  0.000977         0         0  0.000977   \n",
      "2         0         0  0.044922  ...    0.1543         0  0.005859  0.000977   \n",
      "3         0  0.013672  0.017578  ...         0  0.000977         0         0   \n",
      "4         0         0  0.005859  ...   0.09668         0  0.021484         0   \n",
      "..      ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "985       0  0.001953  0.042969  ...   0.24219         0   0.03418         0   \n",
      "986       0  0.029297  0.003906  ...    0.1709         0  0.018555         0   \n",
      "987       0  0.003906         0  ...  0.004883  0.000977  0.004883  0.027344   \n",
      "988       0  0.037109  0.001953  ...  0.083008  0.030273  0.000977   0.00293   \n",
      "989       0  0.003906  0.039062  ...         0         0   0.00293         0   \n",
      "\n",
      "    texture59 texture60 texture61 texture62 texture63 texture64  \n",
      "0    0.035156         0         0  0.004883         0  0.025391  \n",
      "1    0.023438         0         0  0.000977  0.039062  0.022461  \n",
      "2    0.007812         0         0         0  0.020508   0.00293  \n",
      "3    0.020508         0         0  0.017578         0  0.047852  \n",
      "4           0         0         0         0         0   0.03125  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "985  0.010742         0         0         0         0  0.018555  \n",
      "986  0.011719         0         0  0.000977         0  0.021484  \n",
      "987  0.016602  0.007812         0  0.027344         0  0.001953  \n",
      "988  0.014648         0  0.041992         0  0.001953   0.00293  \n",
      "989  0.012695         0         0  0.023438  0.025391  0.022461  \n",
      "\n",
      "[990 rows x 192 columns]\n"
     ]
    }
   ],
   "source": [
    "data_path_train = './data/train.csv'\n",
    "data_path_test = './data/test.csv'\n",
    "\n",
    "#Extract data for training dataset\n",
    "data_attributes_train, data_train_df, ids_train, labels = data_extract(data_path_train,dataset = \"train\")\n",
    "\n",
    "#Extract data for testing dataset\n",
    "res = data_extract(data_path_test,dataset = \"test\")\n",
    "data_attributes_test = res[0]\n",
    "data_test_df = res[1]\n",
    "ids_test = res[2]\n",
    "\n",
    "#Clean data\n",
    "print(data_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# 2. Classification\n",
    "\n",
    "Dans cette partie nous allons mettre en place 6 classifieurs :\n",
    "- Random Forest\n",
    "- Neural Network\n",
    "- SVM\n",
    "- AdaBoost\n",
    "- Decision Tree\n",
    "- KNeighbors\n",
    "- Regression linéaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par Random Forest\n",
    "Une `random forest` est un estimateur qui utilise plusieurs arbres de décision pour palier à la tendance de sur-apprentissage de ceux-ci. Chaque arbre apprend sur les données d'entrée avec des paramètres différents puis l'estimateur classe les points par la probabilité la plus haute pour tout les arbres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Classifieur par réseau de neurones\n",
    "Un réseau de neurones est un algorithme d’apprentissage supervisé de plusiers fonctions d’apprentissage. Il calcule la prédiction et la compare avec la valeur de y à l'aide de la fonction de coût et l'erreur est propagé en arrière afin de mettre à jour les poids des différentes fonctions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par SVM\n",
    "Les machines à vecteurs support (SVM) sont des algorithmes d’apprentissage supervisé  utilisées pour la classification et la régression. Elles reposent souvent sur l’utilisation de noyaux qui permettent de transformer l’espace de représentation des données d’entrées en un espace de plus grande dimension, dans lequel il existe une séparation linéaire, le but est de maximiser la distance entre les groupes de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par Adaboost\n",
    "L’adaptative boosting est un algorithme de boosting qui regroupe plusieurs classifieurs faibles en leur donnant un poids selon leurs performances pour en faire un classifieur fort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par Decision trees\n",
    "Une `decision trees` est un méthode d’apprentissage supervisé non paramétrique pour la classification et la régression. Notre objectif est de créer un modèle qui prédit la valeur de la variable cible en apprenant des règles de décision simples déduites des caractéristiques des données. L’arbre peut être considéré comme une approximation constante par segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par KNeighbors\n",
    "Une `KNeighbors` est une méthode d’apprentissage basé sur des exemples ou d’apprentissage non généralisé. Elle ne cherche pas à construire un modèle interne général, mais simplement à stocker des exemples de données de formation. La classification est calculée à la majorité simple des voisins les plus proches de chaque point: une classe de données est attribuée à un point de requête qui a le plus de représentants parmi les voisins les plus proches de ce point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Classifieur par regression logistique \n",
    "La régression logistique est un algorithme d’apprentissage automatique utilisé dans les problèmes de classification et qui a pour but attribuer des observations à un ensemble discret de classes, c’est un modèle linéaire. Grâce à la fonction sigmoïde logistique, la régression logistique transforme sa sortie en une probabilité d'appartenir à l'une ou à l'autre classe dans le cas binaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# 3. Comparaison des résultats\n",
    "\n",
    "On compile les résultats des classifieurs étudiés pour les comparer sur leur 'accuracy'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "# 4. Conclusions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3d69c228acec43ccb1d94850ec81cd25ddd764b16c8320f7bd382f3b185d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
